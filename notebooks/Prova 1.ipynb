{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 1: Compilação de uns corpora (com no mínimo dois córpus, de domínios textuais diferentes).\n",
    "\n",
    "- Link para cloud do corpus: \n",
    "\n",
    "### Estatisticas dos corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franc_lib import lexical\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from collections import Counter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = lexical.Preprocessing(file_name='a')\n",
    "\n",
    "# Definir o path geral do corpus\n",
    "corpora_path = 'data/corpora'\n",
    "\n",
    "# Arquivos corpus sobre SAUDE\n",
    "files_saude = os.listdir('{}/saude/'.format(corpora_path))\n",
    "files_saude = ['{}/saude/{}'.format(corpora_path,f) for f in files_saude if f != '.DS_Store']\n",
    "\n",
    "tokens_saude = []\n",
    "media_saude = 0\n",
    "\n",
    "media_sentencas_saude = 0\n",
    "qtd_sentencas = 0\n",
    "\n",
    "for file in files_saude:\n",
    "    with open(file, 'r') as text_file:\n",
    "        lines = text_file.readlines()\n",
    "        for line in lines:\n",
    "#           Converte todos os caracteres para letra minusculas\n",
    "            line = normalizer.lowercase(line)\n",
    "            sentences = normalizer.tokenize_sentences(line, save=False)\n",
    "            sentences = normalizer.remove_punctuation(sentences, save=False)\n",
    "            \n",
    "            qtd_sentencas += len(sentences)\n",
    "            \n",
    "            for sentence in sentences:\n",
    "                tokens = normalizer.tokenize_words(sentence)\n",
    "                media_sentencas_saude += len(tokens)\n",
    "                for token in tokens: tokens_saude.append(token)\n",
    "            \n",
    "media_saude = sum(len(token) for token in tokens_saude) / len(tokens_saude)\n",
    "media_sentencas_saude = media_sentencas_saude / qtd_sentencas\n",
    "\n",
    "# Corpus POLITICA\n",
    "files_politica = os.listdir('{}/politica/'.format(corpora_path))\n",
    "files_politica = ['{}/politica/{}'.format(corpora_path,f) for f in files_politica if f != '.DS_Store']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "contagem_saude = Counter(tokens_saude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 20 palavras mais frequentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('de', 20819)\n",
      "('a', 14628)\n",
      "('que', 11882)\n",
      "('e', 11583)\n",
      "('o', 11205)\n",
      "('do', 5942)\n",
      "('da', 5644)\n",
      "('é', 5562)\n",
      "('em', 5539)\n",
      "('para', 4981)\n",
      "('com', 4161)\n",
      "('não', 4160)\n",
      "('um', 4148)\n",
      "('os', 4064)\n",
      "('uma', 3568)\n",
      "('no', 3311)\n",
      "('por', 3009)\n",
      "('se', 2905)\n",
      "('mais', 2857)\n",
      "('na', 2652)\n"
     ]
    }
   ],
   "source": [
    "for dic in contagem_saude.most_common(20):\n",
    "    print(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 20 palavras menos frequentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('hess', 1)\n",
      "('famíliadiscuta', 1)\n",
      "('etcnas', 1)\n",
      "('eficáciaum', 1)\n",
      "('arrais', 1)\n",
      "('italianoele', 1)\n",
      "('pesquisadorreferência', 1)\n",
      "('troppa', 1)\n",
      "('ingerilo', 1)\n",
      "('1907', 1)\n",
      "('facilitaram', 1)\n",
      "('combatêlo', 1)\n",
      "('quiseram', 1)\n",
      "('denguesorocaba', 1)\n",
      "('reclamante', 1)\n",
      "('singapuraultrassom', 1)\n",
      "('ofensa', 1)\n",
      "('technology', 1)\n",
      "('geladeira…', 1)\n",
      "('tireoidianoscausasdoença', 1)\n"
     ]
    }
   ],
   "source": [
    "for dic in contagem_saude.most_common()[-20:]:\n",
    "    print(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tamanho médio das palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O tamanho médio das PALAVRAS no corpus sobre SAÚDE é: 5.16\n"
     ]
    }
   ],
   "source": [
    "print(\"O tamanho médio das PALAVRAS no corpus sobre SAÚDE é: %.2f\" % media_saude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tamanho médio das sentenças, em números de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O tamanho médio das SENTENCAS no corpus sobre SAÚDE é: 31.43\n"
     ]
    }
   ],
   "source": [
    "print(\"O tamanho médio das SENTENCAS no corpus sobre SAÚDE é: %.2f\" % media_sentencas_saude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
