{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prova 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 1: Compilação de uns corpora (com no mínimo dois córpus, de domínios textuais diferentes).\n",
    "\n",
    "- Link para cloud do corpus: https://drive.google.com/file/d/1FawgaGuxs6tvMfz0wcVnk6FKPB0rSLG-/view?usp=sharing\n",
    "\n",
    "### Estatisticas dos corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação da minha lib de normalização\n",
    "from franc_lib import lexical\n",
    "# Import dos metodos e funções do word2vec\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "# Collection para contagem de palavras\n",
    "from collections import Counter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nova instancia do pre processador\n",
    "normalizer = lexical.Preprocessing()\n",
    "\n",
    "# Definir o path geral do corpus\n",
    "corpora_path = 'data/corpora'\n",
    "\n",
    "# Arquivos corpus sobre SAUDE\n",
    "files_saude = os.listdir('{}/saude/'.format(corpora_path))\n",
    "files_saude = ['{}/saude/{}'.format(corpora_path,f) for f in files_saude if f != '.DS_Store']\n",
    "\n",
    "# Processamento do corpus de saude #\n",
    "# Salva todas as sentencas em uma lista de lista para o word2vec\n",
    "all_sentences_saude = []\n",
    "# Isola os tokens em apenas uma lista para a contagem de palavras\n",
    "tokens_saude = []\n",
    "# Variaveis dos dados estatisticos\n",
    "media_saude = 0\n",
    "media_sentencas_saude = 0\n",
    "qtd_sentencas = 0\n",
    "\n",
    "# Para cada arquivo no corpus faça\n",
    "for file in files_saude:\n",
    "    with open(file, 'r') as text_file:\n",
    "        lines = text_file.readlines()\n",
    "        for line in lines:\n",
    "#           Converte todos os caracteres para letra minusculas\n",
    "            line = normalizer.lowercase(line)\n",
    "#           Remove todos os acentos\n",
    "            line = normalizer.remove_accents(line)\n",
    "#           Tokeniza as sentencas sem salvar os arquivos temporarios\n",
    "            sentences = normalizer.tokenize_sentences(line, save=False)\n",
    "#           Remove as pontuações\n",
    "            sentences = normalizer.remove_punctuation(sentences, save=False)\n",
    "            \n",
    "#           Incrementa a quantidade de sentenças\n",
    "            qtd_sentencas += len(sentences)\n",
    "            \n",
    "            for sentence in sentences:\n",
    "                tokens = normalizer.tokenize_words(sentence)\n",
    "                tokens = normalizer.remove_stopwords(tokens, save=False)\n",
    "                all_sentences_saude.append(tokens)\n",
    "                \n",
    "                media_sentencas_saude += len(tokens)\n",
    "                for token in tokens: tokens_saude.append(token)\n",
    "            \n",
    "media_saude = sum(len(token) for token in tokens_saude) / len(tokens_saude)\n",
    "media_sentencas_saude = media_sentencas_saude / qtd_sentencas\n",
    "\n",
    "# Corpus POLITICA\n",
    "files_politica = os.listdir('{}/politica/'.format(corpora_path))\n",
    "files_politica = ['{}/politica/{}'.format(corpora_path,f) for f in files_politica if f != '.DS_Store']\n",
    "\n",
    "all_sentences_politica = []\n",
    "tokens_politica = []\n",
    "media_politica = 0\n",
    "media_sentencas_politica = 0\n",
    "qtd_sentencas_politica = 0\n",
    "\n",
    "for file in files_politica:\n",
    "    with open(file, 'r') as text_file:\n",
    "        lines = text_file.readlines()\n",
    "        for line in lines:\n",
    "#           Converte todos os caracteres para letra minusculas\n",
    "            line = normalizer.lowercase(line)\n",
    "            line = normalizer.remove_accents(line)\n",
    "            sentences = normalizer.tokenize_sentences(line, save=False)\n",
    "            sentences = normalizer.remove_punctuation(sentences, save=False)\n",
    "            \n",
    "            qtd_sentencas_politica += len(sentences)\n",
    "            \n",
    "            for sentence in sentences:\n",
    "                tokens = normalizer.tokenize_words(sentence)\n",
    "                tokens = normalizer.remove_stopwords(tokens, save=False)\n",
    "                all_sentences_politica.append(tokens)\n",
    "                \n",
    "                media_sentencas_politica += len(tokens)\n",
    "                for token in tokens: tokens_politica.append(token)\n",
    "            \n",
    "media_politica = sum(len(token) for token in tokens_saude) / len(tokens_politica)\n",
    "media_sentencas_politica = media_sentencas_politica / qtd_sentencas_politica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "contagem_saude = Counter(tokens_saude)\n",
    "contagem_politica = Counter(tokens_politica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 20 palavras mais frequentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As palavras mais comuns no corpus SAÚDE são: \n",
      "('nao', 4161)\n",
      "('a', 3434)\n",
      "('o', 3169)\n",
      "('que', 2963)\n",
      "('um', 1910)\n",
      "('sao', 1731)\n",
      "('uma', 1576)\n",
      "('ser', 1560)\n",
      "('pode', 1273)\n",
      "('anos', 1073)\n",
      "('os', 1070)\n",
      "('saude', 1023)\n",
      "('sobre', 963)\n",
      "('pessoas', 953)\n",
      "('de', 933)\n",
      "('tambem', 925)\n",
      "('se', 818)\n",
      "('ha', 787)\n",
      "('ja', 766)\n",
      "('doenca', 764)\n"
     ]
    }
   ],
   "source": [
    "print(\"As palavras mais comuns no corpus SAÚDE são: \")\n",
    "for dic in contagem_saude.most_common(20):\n",
    "    print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As palavras mais comuns no corpus POLITICA são: \n",
      "('nao', 5215)\n",
      "('o', 4804)\n",
      "('a', 4037)\n",
      "('que', 3442)\n",
      "('bolsonaro', 2506)\n",
      "('um', 2191)\n",
      "('sobre', 2054)\n",
      "('uma', 1760)\n",
      "('presidente', 1742)\n",
      "('governo', 1430)\n",
      "('globo', 1364)\n",
      "('tambem', 1357)\n",
      "('ser', 1248)\n",
      "('brasil', 1161)\n",
      "('anos', 1105)\n",
      "('sao', 1071)\n",
      "('politica', 1061)\n",
      "('se', 1050)\n",
      "('lula', 1037)\n",
      "('disse', 997)\n"
     ]
    }
   ],
   "source": [
    "print(\"As palavras mais comuns no corpus POLITICA são: \")\n",
    "for dic in contagem_politica.most_common(20):\n",
    "    print(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 20 palavras menos frequentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As palavras menos comuns no corpus SAÚDE são: \n",
      "('reunia', 1)\n",
      "('2019horario', 1)\n",
      "('bortoletto', 1)\n",
      "('miudoscomo', 1)\n",
      "('climaticasnesta', 1)\n",
      "('conjuntoou', 1)\n",
      "('imunologicoante', 1)\n",
      "('quilograma', 1)\n",
      "('passageiro', 1)\n",
      "('criogeniauma', 1)\n",
      "('corporalde', 1)\n",
      "('invocam', 1)\n",
      "('escovaindependentemente', 1)\n",
      "('korsakoff', 1)\n",
      "('ativosprodutos', 1)\n",
      "('disparada', 1)\n",
      "('annesexames', 1)\n",
      "('michele', 1)\n",
      "('briefing', 1)\n",
      "('domicilio', 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"As palavras menos comuns no corpus SAÚDE são: \")\n",
    "for dic in contagem_saude.most_common()[-20:]:\n",
    "    print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As palavras menos comuns no corpus POLITICA são: \n",
      "('felicianocopyright', 1)\n",
      "('bemeducada', 1)\n",
      "('motivoem', 1)\n",
      "('rejeitando', 1)\n",
      "('ressuscitada', 1)\n",
      "('reunia', 1)\n",
      "('morado', 1)\n",
      "('humboldt', 1)\n",
      "('investigadorescopyright', 1)\n",
      "('encontroemidio', 1)\n",
      "('volkisch', 1)\n",
      "('necessarioprisao', 1)\n",
      "('thronicke', 1)\n",
      "('ekrea', 1)\n",
      "('substituilo', 1)\n",
      "('disparada', 1)\n",
      "('vemconfira', 1)\n",
      "('taciturno', 1)\n",
      "('verificados', 1)\n",
      "('instituicoeso', 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"As palavras menos comuns no corpus POLITICA são: \")\n",
    "for dic in contagem_politica.most_common()[-20:]:\n",
    "    print(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tamanho médio das palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O tamanho médio das PALAVRAS no corpus sobre SAÚDE é: 6.65\n",
      "O tamanho médio das PALAVRAS no corpus sobre POLITICA é: 5.07\n"
     ]
    }
   ],
   "source": [
    "print(\"O tamanho médio das PALAVRAS no corpus sobre SAÚDE é: %.2f\" % media_saude)\n",
    "print(\"O tamanho médio das PALAVRAS no corpus sobre POLITICA é: %.2f\" % media_politica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tamanho médio das sentenças, em números de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O tamanho médio das SENTENCAS no corpus sobre SAÚDE é: 20.08\n",
      "O tamanho médio das SENTENCAS no corpus sobre POLITICA é: 20.34\n"
     ]
    }
   ],
   "source": [
    "print(\"O tamanho médio das SENTENCAS no corpus sobre SAÚDE é: %.2f\" % media_sentencas_saude)\n",
    "print(\"O tamanho médio das SENTENCAS no corpus sobre POLITICA é: %.2f\" % media_sentencas_politica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quantidade de sentenças no corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A quantidade de sentenças no corpus sobre SAUDE é: 14052.00\n",
      "A quantidade de sentenças no corpus sobre POLITICA é: 18194.00\n"
     ]
    }
   ],
   "source": [
    "print(\"A quantidade de sentenças no corpus sobre SAUDE é: %.2f\" % qtd_sentencas)\n",
    "print(\"A quantidade de sentenças no corpus sobre POLITICA é: %.2f\" % qtd_sentencas_politica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quantidade de documentos nos corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A quantidade de documentos no corpus sobre SAUDE é: 735.00\n",
      "A quantidade de documentos no corpus sobre POLITICA é: 1004.00\n"
     ]
    }
   ],
   "source": [
    "print(\"A quantidade de documentos no corpus sobre SAUDE é: %.2f\" % len(files_saude))\n",
    "print(\"A quantidade de documentos no corpus sobre POLITICA é: %.2f\" % len(files_politica))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 3: Normalização dos Corpus para o Word2Vec e Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento para o corpus sobre SAUDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size: tamanho do vetor que representa as palavras, window: janela de palavras para contexto, \n",
    "# min_count: minimo de palavras para ser considerada, workers: \n",
    "w2vmodel_saude = Word2Vec(all_sentences_saude, size=200, window=2, min_count=3, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tratamento', 0.997723400592804),\n",
       " ('paciente', 0.996816098690033),\n",
       " ('que', 0.9952199459075928),\n",
       " ('problema', 0.994949221611023),\n",
       " ('ajudar', 0.9940050840377808),\n",
       " ('porque', 0.9938564300537109),\n",
       " ('so', 0.9936471581459045),\n",
       " ('melhor', 0.9934467077255249),\n",
       " ('isso', 0.9933716654777527),\n",
       " ('vida', 0.9930479526519775)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vmodel_saude.wv.most_similar('doenca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('educacao', 0.9793803691864014),\n",
       " ('organizacao', 0.9781202077865601),\n",
       " ('cultura', 0.9773637056350708),\n",
       " ('estacao', 0.9745335578918457),\n",
       " ('universo', 0.9719486236572266),\n",
       " ('ltda', 0.9712579250335693),\n",
       " ('novidades', 0.9708921909332275),\n",
       " ('veiculadas', 0.9702247381210327),\n",
       " ('videosdicas', 0.968104898929596),\n",
       " ('ciencia', 0.9680289626121521)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vmodel_saude.wv.most_similar('saude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ilustracao', 0.997657299041748),\n",
       " ('academia', 0.997603178024292),\n",
       " ('olho', 0.9976019859313965),\n",
       " ('avicii', 0.997592568397522),\n",
       " ('funcoes', 0.9975890517234802),\n",
       " ('carlos', 0.9975818395614624),\n",
       " ('atividades', 0.9975677728652954),\n",
       " ('cuja', 0.9975597858428955),\n",
       " ('presidente', 0.9975561499595642),\n",
       " ('nosso', 0.9975557923316956)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vmodel_saude.wv.most_similar('dst')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento para o corpus sobre POLITICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vmodel_politica = Word2Vec(all_sentences_politica, size=200, window=4, min_count=3, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('previdencia', 0.984020471572876),\n",
       " ('proposta', 0.9240491390228271),\n",
       " ('aprova', 0.9176387786865234),\n",
       " ('previdenciao', 0.914893627166748),\n",
       " ('aprovada', 0.9098544120788574),\n",
       " ('previdenciagoverno', 0.9094251394271851),\n",
       " ('admissibilidade', 0.9026263952255249),\n",
       " ('anticrime', 0.8930299878120422),\n",
       " ('aprovacao', 0.8880246877670288),\n",
       " ('desconstitucionalizacao', 0.8809003829956055)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vmodel_politica.wv.most_similar('reforma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('deixar', 0.9820922613143921),\n",
       " ('feito', 0.9806278944015503),\n",
       " ('fato', 0.9793344140052795),\n",
       " ('chamava', 0.9788445830345154),\n",
       " ('julgado', 0.9786261320114136),\n",
       " ('nasce', 0.9781030416488647),\n",
       " ('apesar', 0.9769169688224792),\n",
       " ('visto', 0.9763909578323364),\n",
       " ('adriane', 0.9759719371795654),\n",
       " ('companheiro', 0.9751474857330322)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vmodel_politica.wv.most_similar('corrupto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tenho', 0.9902435541152954),\n",
       " ('certeza', 0.9874128699302673),\n",
       " ('ficado', 0.9865046143531799),\n",
       " ('merece', 0.9862920045852661),\n",
       " ('sair', 0.9862432479858398),\n",
       " ('bom', 0.9859268069267273),\n",
       " ('fazerem', 0.9852614402770996),\n",
       " ('terroristas', 0.9848560690879822),\n",
       " ('como', 0.9844812750816345),\n",
       " ('colocar', 0.9841873645782471)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vmodel_politica.wv.most_similar('inocente')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Discuta como poderia melhorar os\tresultados.\tPense no nível da morfologia ou\toutro do PLN:\n",
    "\n",
    "R: Para melhor os resultados dessas comparações poderiam ser adicionados mais documentos nos dominios textuais de cada corpus, o que melhoraria a precisão e o treinamento do Word2Vec. Além disso poderia ser feito um outro pré-processamento nos texto a fim de melhorar e corrigir palavras escritas de forma errônea (usando até mesmo outra tecnica de IA para fazer esse pré-processamento), e uma outra alternativa seria filtrar melhor as fontes de texto para melhorar a confiabilidade dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos corpus para o Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 1739\n"
     ]
    }
   ],
   "source": [
    "all_documents = []\n",
    "all_files = files_saude\n",
    "all_files.extend(files_politica)\n",
    "for file in all_files:\n",
    "    with open(file, 'r') as text_file:\n",
    "        document = ' '.join(text_file.readlines())\n",
    "        document = normalizer.lowercase(document)\n",
    "        document_tokens = normalizer.tokenize_words(document)\n",
    "        all_documents.append(document_tokens)\n",
    "print(\"Number of documents: {}\".format(len(all_documents)))\n",
    "tagged_documents = [TaggedDocument(words=d, tags=[str(i)]) for i, d in enumerate(all_documents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2vmodel = Doc2Vec(tagged_documents, vector_size=20, window=2, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 4: Uso do Doc2Vec\n",
    "\n",
    "#### Dados\tos\tdocumentos\t(textos) de\tcorporas\tdiferentes,\tutilize\tos\tvetores\tpara encontrar\tos\tdocumentos\tmais\tsimilares\n",
    "\n",
    "    - Exemplifique com três documentos e discuta os resultados. Ao ser ver, foram bons? Os documentos realmente são parecidos? O que poderia ser feito para melhorar os resultados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplos de documentos similiares: \n",
      "\n",
      "Documentos similares ao documento: data/corpora/saude/drauziovarella_uol_com_br-cardiovascular-o-que-e-um-infarto-fulminante-.txt \n",
      "\n",
      "99º Documento => data/corpora/saude/drauziovarella_uol_com_br-drauzio-artigos-pressao-alta-artigo-.txt\n",
      "\n",
      "9º Documento => data/corpora/saude/drauziovarella_uol_com_br-diabetes-sintomas-chaves-que-podem-indicar-diabetes-.txt\n",
      "\n",
      "94º Documento => data/corpora/saude/www1_folha_uol_com_br-equilibrioesaude-2017-03-1869080-dois-tercos-dos-casos-de-cancer-sao-por-falta-de-sorte_shtml.txt\n",
      "\n",
      "3º Documento => data/corpora/saude/drauziovarella_uol_com_br-reportagens-por-que-a-obesidade-e-considerada-doenca-cronica-.txt\n",
      "\n",
      "256º Documento => data/corpora/saude/drauziovarella_uol_com_br-entrevistas-2-nodulos-na-tireoide-entrevista-.txt\n",
      "=========================================================\n",
      "\n",
      "Documentos similares ao documento: data/corpora/saude/www1_folha_uol_com_br-equilibrioesaude-2017-11-1938873-metade-dos-jovens-brasileiros-entre-16-e-25-anos-tem-hpv-estima-pesquisa_shtml.txt \n",
      "\n",
      "1335º Documento => data/corpora/politica/www_pragmatismopolitico_com_br-2019-03-atiradores-massacre-suzano-dogolachan_html.txt\n",
      "\n",
      "321º Documento => data/corpora/saude/www1_folha_uol_com_br-equilibrioesaude-2019-04-quantidade-abaixo-da-recomendada-de-bacon-e-carne-bovina-eleva-risco-de-cancer_shtml.txt\n",
      "\n",
      "1404º Documento => data/corpora/politica/blogs_oglobo_globo_com-lauro-jardim-post-bolsonaro-americano-como-o-brasileiro-ve-trump-nas-redes-sociais_html.txt\n",
      "\n",
      "848º Documento => data/corpora/politica/blogs_oglobo_globo_com-lauro-jardim-post-em-1992-bolsonaro-era-muito-mais-comportado_html.txt\n",
      "\n",
      "414º Documento => data/corpora/saude/drauziovarella_uol_com_br-corpo-humano-tireoide-.txt\n",
      "=========================================================\n",
      "\n",
      "Documentos similares ao documento: data/corpora/saude/saude_abril_com_br-blog-cientistas-explicam-virus-da-gripe-por-que-todo-ano-temos-uma-luta-e-uma-vacina-diferente-.txt \n",
      "\n",
      "670º Documento => data/corpora/saude/saude_abril_com_br-blog-e-verdade-ou-fake-news-guardar-a-cebola-cortada-e-um-veneno-para-a-saude-checamos-essa-historia-.txt\n",
      "\n",
      "1721º Documento => data/corpora/politica/www_pragmatismopolitico_com_br-2019-04-caos-impera-brasil-acaso-e-projeto_html.txt\n",
      "\n",
      "462º Documento => data/corpora/saude/saude_abril_com_br-blog-cientistas-explicam-poliomielite-uma-gotinha-de-bom-senso-.txt\n",
      "\n",
      "306º Documento => data/corpora/saude/saude_abril_com_br-blog-tunel-do-tempo-brasileiro-recria-cerebro-neandertal-para-entender-como-chegamos-ate-aqui-.txt\n",
      "\n",
      "597º Documento => data/corpora/saude/saude_abril_com_br-blog-e-verdade-ou-fake-news-videos-mostram-como-salvar-vitimas-do-avc-com-uma-agulha-mas-sao-fake-.txt\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "#numero de documentos similares que deseja procurar\n",
    "topn = 5\n",
    "\n",
    "#posicao do documento na lista all_documentos que deseja procurar documentos similares\n",
    "n_doc = 30\n",
    "n_doc1 = 125\n",
    "n_doc2 = 700\n",
    "\n",
    "print(\"Exemplos de documentos similiares: \")\n",
    "print(\"\")\n",
    "print(\"Documentos similares ao documento: %s \" % all_files[n_doc])\n",
    "similar_doc = d2vmodel.docvecs.most_similar(n_doc, topn=topn)\n",
    "for doc_num in similar_doc:\n",
    "    print(\"\")\n",
    "    print(\"%dº Documento => %s\" % (int(doc_num[0]), all_files[int(doc_num[0])]))\n",
    "print(\"=========================================================\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"Documentos similares ao documento: %s \" % all_files[n_doc1])\n",
    "similar_doc = d2vmodel.docvecs.most_similar(n_doc1, topn=topn)\n",
    "for doc_num in similar_doc:\n",
    "    print(\"\")\n",
    "    print(\"%dº Documento => %s\" % (int(doc_num[0]), all_files[int(doc_num[0])]))\n",
    "print(\"=========================================================\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"Documentos similares ao documento: %s \" % all_files[n_doc2])\n",
    "similar_doc = d2vmodel.docvecs.most_similar(n_doc2, topn=topn)\n",
    "for doc_num in similar_doc:\n",
    "    print(\"\")\n",
    "    print(\"%dº Documento => %s\" % (int(doc_num[0]), all_files[int(doc_num[0])]))\n",
    "print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ao ser ver, foram\tbons? Os documentos\trealmente são parecidos? O que poderia ser feito para melhorar os resultados?\n",
    "\n",
    "No primeiro caso o documento teve uma maior indice de acerto e os dominios textuais foram bastante similiares, tento até mesmo uma certa relação, visto que se tratavam de doenças cardiacas e suas causas. O segundo exemplo houveram partes similares, mas em alguns casos o Doc2vec não conseguiu definir bem os dominios textuais. E o ultimo exemplo também apresentou bons resultados seguindo o dominio textual da saude e encontrando até mesmo questoes referente a suade no dominio da politica. Como já cidad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
