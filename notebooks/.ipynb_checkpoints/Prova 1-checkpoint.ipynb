{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 1: Compilação de uns corpora (com no mínimo dois córpus, de domínios textuais diferentes).\n",
    "\n",
    "- Link para cloud do corpus: \n",
    "\n",
    "### Estatisticas dos corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação da minha lib de normalização\n",
    "from franc_lib import lexical\n",
    "# Import dos metodos e funções do word2vec\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "# Collection para contagem de palavras\n",
    "from collections import Counter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nova instancia do pre processador\n",
    "normalizer = lexical.Preprocessing()\n",
    "\n",
    "# Definir o path geral do corpus\n",
    "corpora_path = 'data/corpora'\n",
    "\n",
    "# Arquivos corpus sobre SAUDE\n",
    "files_saude = os.listdir('{}/saude/'.format(corpora_path))\n",
    "files_saude = ['{}/saude/{}'.format(corpora_path,f) for f in files_saude if f != '.DS_Store']\n",
    "\n",
    "# Processamento do corpus de saude #\n",
    "# Salva todas as sentencas em uma lista de lista para o word2vec\n",
    "all_sentences_saude = []\n",
    "# Isola os tokens em apenas uma lista para a contagem de palavras\n",
    "tokens_saude = []\n",
    "# Variaveis dos dados estatisticos\n",
    "media_saude = 0\n",
    "media_sentencas_saude = 0\n",
    "qtd_sentencas = 0\n",
    "\n",
    "# Para cada arquivo no corpus faça\n",
    "for file in files_saude:\n",
    "    with open(file, 'r') as text_file:\n",
    "        lines = text_file.readlines()\n",
    "        for line in lines:\n",
    "#           Converte todos os caracteres para letra minusculas\n",
    "            line = normalizer.lowercase(line)\n",
    "#           Remove todos os acentos\n",
    "            line = normalizer.remove_accents(line)\n",
    "#           Tokeniza as sentencas sem salvar os arquivos temporarios\n",
    "            sentences = normalizer.tokenize_sentences(line, save=False)\n",
    "#           Remove as pontuações\n",
    "            sentences = normalizer.remove_punctuation(sentences, save=False)\n",
    "            \n",
    "#           Incrementa a quantidade de sentenças\n",
    "            qtd_sentencas += len(sentences)\n",
    "            \n",
    "            for sentence in sentences:\n",
    "                tokens = normalizer.tokenize_words(sentence)\n",
    "                tokens = normalizer.remove_stopwords(tokens, save=False)\n",
    "                all_sentences_saude.append(tokens)\n",
    "                \n",
    "                media_sentencas_saude += len(tokens)\n",
    "                for token in tokens: tokens_saude.append(token)\n",
    "            \n",
    "media_saude = sum(len(token) for token in tokens_saude) / len(tokens_saude)\n",
    "media_sentencas_saude = media_sentencas_saude / qtd_sentencas\n",
    "\n",
    "# Corpus POLITICA\n",
    "files_politica = os.listdir('{}/politica/'.format(corpora_path))\n",
    "files_politica = ['{}/politica/{}'.format(corpora_path,f) for f in files_politica if f != '.DS_Store']\n",
    "\n",
    "all_sentences_politica = []\n",
    "tokens_politica = []\n",
    "media_politica = 0\n",
    "media_sentencas_politica = 0\n",
    "qtd_sentencas_politica = 0\n",
    "\n",
    "for file in files_politica:\n",
    "    with open(file, 'r') as text_file:\n",
    "        lines = text_file.readlines()\n",
    "        for line in lines:\n",
    "#           Converte todos os caracteres para letra minusculas\n",
    "            line = normalizer.lowercase(line)\n",
    "            line = normalizer.remove_accents(line)\n",
    "            sentences = normalizer.tokenize_sentences(line, save=False)\n",
    "            sentences = normalizer.remove_punctuation(sentences, save=False)\n",
    "            \n",
    "            qtd_sentencas_politica += len(sentences)\n",
    "            \n",
    "            for sentence in sentences:\n",
    "                tokens = normalizer.tokenize_words(sentence)\n",
    "                tokens = normalizer.remove_stopwords(tokens, save=False)\n",
    "                all_sentences_politica.append(tokens)\n",
    "                \n",
    "                media_sentencas_politica += len(tokens)\n",
    "                for token in tokens: tokens_politica.append(token)\n",
    "            \n",
    "media_politica = sum(len(token) for token in tokens_saude) / len(tokens_politica)\n",
    "media_sentencas_politica = media_sentencas_politica / qtd_sentencas_politica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "contagem_saude = Counter(tokens_saude)\n",
    "contagem_politica = Counter(tokens_politica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 20 palavras mais frequentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As palavras mais comuns no corpus SAÚDE são: \n",
      "('nao', 4161)\n",
      "('a', 3434)\n",
      "('o', 3169)\n",
      "('que', 2963)\n",
      "('um', 1910)\n",
      "('sao', 1731)\n",
      "('uma', 1576)\n",
      "('ser', 1560)\n",
      "('pode', 1273)\n",
      "('anos', 1073)\n",
      "('os', 1070)\n",
      "('saude', 1023)\n",
      "('sobre', 963)\n",
      "('pessoas', 953)\n",
      "('de', 933)\n",
      "('tambem', 925)\n",
      "('se', 818)\n",
      "('ha', 787)\n",
      "('ja', 766)\n",
      "('doenca', 764)\n"
     ]
    }
   ],
   "source": [
    "print(\"As palavras mais comuns no corpus SAÚDE são: \")\n",
    "for dic in contagem_saude.most_common(20):\n",
    "    print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As palavras mais comuns no corpus POLITICA são: \n",
      "('nao', 5215)\n",
      "('o', 4809)\n",
      "('a', 4037)\n",
      "('que', 3442)\n",
      "('bolsonaro', 2506)\n",
      "('um', 2191)\n",
      "('sobre', 2069)\n",
      "('uma', 1760)\n",
      "('presidente', 1742)\n",
      "('governo', 1430)\n",
      "('globo', 1389)\n",
      "('tambem', 1362)\n",
      "('ser', 1248)\n",
      "('brasil', 1166)\n",
      "('anos', 1110)\n",
      "('sao', 1071)\n",
      "('politica', 1071)\n",
      "('se', 1055)\n",
      "('lula', 1037)\n",
      "('disse', 997)\n"
     ]
    }
   ],
   "source": [
    "print(\"As palavras mais comuns no corpus POLITICA são: \")\n",
    "for dic in contagem_politica.most_common(20):\n",
    "    print(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 20 palavras menos frequentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As palavras menos comuns no corpus SAÚDE são: \n",
      "('afirmauma', 1)\n",
      "('pelecirurgiadiabetesmedicamentos', 1)\n",
      "('fimum', 1)\n",
      "('explorado', 1)\n",
      "('tifo', 1)\n",
      "('lanolina', 1)\n",
      "('entupimentos', 1)\n",
      "('montanha', 1)\n",
      "('minimizala', 1)\n",
      "('reduzia', 1)\n",
      "('pacientescopyright', 1)\n",
      "('geleias', 1)\n",
      "('bacteriologista', 1)\n",
      "('resistiuo', 1)\n",
      "('poscirurgia', 1)\n",
      "('imunoterapiaestamos', 1)\n",
      "('neurodegenerativos', 1)\n",
      "('usppor', 1)\n",
      "('mogi', 1)\n",
      "('incontinenciaquando', 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"As palavras menos comuns no corpus SAÚDE são: \")\n",
    "for dic in contagem_saude.most_common()[-20:]:\n",
    "    print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As palavras menos comuns no corpus POLITICA são: \n",
      "('comportou', 1)\n",
      "('imprensaele', 1)\n",
      "('profissionalizante', 1)\n",
      "('itauoutro', 1)\n",
      "('diretorapresidente', 1)\n",
      "('montanha', 1)\n",
      "('georgetown', 1)\n",
      "('manifestos', 1)\n",
      "('compatibilidade', 1)\n",
      "('cristalizadas', 1)\n",
      "('enganar', 1)\n",
      "('contara', 1)\n",
      "('cartacapitalroberto', 1)\n",
      "('intento', 1)\n",
      "('hollywood', 1)\n",
      "('cusparada', 1)\n",
      "('livredilma', 1)\n",
      "('afirmouja', 1)\n",
      "('absolver', 1)\n",
      "('vasectomia', 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"As palavras menos comuns no corpus POLITICA são: \")\n",
    "for dic in contagem_politica.most_common()[-20:]:\n",
    "    print(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tamanho médio das palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O tamanho médio das PALAVRAS no corpus sobre SAÚDE é: 6.65\n",
      "O tamanho médio das PALAVRAS no corpus sobre POLITICA é: 5.06\n"
     ]
    }
   ],
   "source": [
    "print(\"O tamanho médio das PALAVRAS no corpus sobre SAÚDE é: %.2f\" % media_saude)\n",
    "print(\"O tamanho médio das PALAVRAS no corpus sobre POLITICA é: %.2f\" % media_politica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tamanho médio das sentenças, em números de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O tamanho médio das SENTENCAS no corpus sobre SAÚDE é: 20.08\n",
      "O tamanho médio das SENTENCAS no corpus sobre POLITICA é: 20.34\n"
     ]
    }
   ],
   "source": [
    "print(\"O tamanho médio das SENTENCAS no corpus sobre SAÚDE é: %.2f\" % media_sentencas_saude)\n",
    "print(\"O tamanho médio das SENTENCAS no corpus sobre POLITICA é: %.2f\" % media_sentencas_politica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quantidade de sentenças no corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A quantidade de sentenças no corpus sobre SAUDE é: 14052.00\n",
      "A quantidade de sentenças no corpus sobre POLITICA é: 18219.00\n"
     ]
    }
   ],
   "source": [
    "print(\"A quantidade de sentenças no corpus sobre SAUDE é: %.2f\" % qtd_sentencas)\n",
    "print(\"A quantidade de sentenças no corpus sobre POLITICA é: %.2f\" % qtd_sentencas_politica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 3: Normalização dos Corpus para o Word2Vec e Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento para o corpus sobre SAUDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size: tamanho do vetor que representa as palavras, window: janela de palavras para contexto, \n",
    "# min_count: minimo de palavras para ser considerada, workers: \n",
    "w2vmodel_saude = Word2Vec(all_sentences_saude, size=200, window=2, min_count=3, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tratamento', 0.9961840510368347),\n",
       " ('paciente', 0.9937943816184998),\n",
       " ('que', 0.9924705028533936),\n",
       " ('tambem', 0.9918035864830017),\n",
       " ('encaminhado', 0.9913858771324158),\n",
       " ('confundido', 0.9913596510887146),\n",
       " ('hipertensao', 0.9913403391838074),\n",
       " ('isso', 0.9913114309310913),\n",
       " ('vida', 0.9911888837814331),\n",
       " ('demorar', 0.9911772012710571)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vmodel_saude.wv.most_similar('doenca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('educacao', 0.9814133644104004),\n",
       " ('cultura', 0.9781449437141418),\n",
       " ('mundial', 0.9775398969650269),\n",
       " ('organizacao', 0.9771041870117188),\n",
       " ('estacao', 0.9764307141304016),\n",
       " ('veiculadas', 0.9742909669876099),\n",
       " ('publica', 0.9721012115478516),\n",
       " ('universo', 0.9720121622085571),\n",
       " ('ministerio', 0.9719089269638062),\n",
       " ('ltda', 0.9709968566894531)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vmodel_saude.wv.most_similar('saude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('apresentaram', 0.997307538986206),\n",
       " ('herpes', 0.997231125831604),\n",
       " ('entrevistados', 0.9972265958786011),\n",
       " ('ficou', 0.997219443321228),\n",
       " ('britanico', 0.9971963763237),\n",
       " ('modelo', 0.9971953630447388),\n",
       " ('protecao', 0.9971714615821838),\n",
       " ('foto', 0.9971486330032349),\n",
       " ('superior', 0.9971370100975037),\n",
       " ('maos', 0.9971342086791992)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vmodel_saude.wv.most_similar('dst')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento para o corpus sobre POLITICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vmodel_politica = Word2Vec(all_sentences_politica, size=200, window=4, min_count=3, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('previdencia', 0.9750304222106934),\n",
       " ('proposta', 0.9371159672737122),\n",
       " ('previdenciao', 0.9255030155181885),\n",
       " ('desconstitucionalizacao', 0.9153079986572266),\n",
       " ('levara', 0.9083378314971924),\n",
       " ('admissibilidade', 0.9073651432991028),\n",
       " ('aprovada', 0.8994948267936707),\n",
       " ('aprovacao', 0.8977468013763428),\n",
       " ('sobrevive', 0.8943605422973633),\n",
       " ('anticrimea', 0.8840730786323547)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vmodel_politica.wv.most_similar('reforma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tomei', 0.9814298152923584),\n",
       " ('interrompe', 0.9790982604026794),\n",
       " ('recorrer', 0.9783773422241211),\n",
       " ('provisoriamente', 0.9771593809127808),\n",
       " ('analisada', 0.9761959314346313),\n",
       " ('criminalista', 0.9761179089546204),\n",
       " ('colegiado', 0.9759895205497742),\n",
       " ('lulaa', 0.9755644798278809),\n",
       " ('considera', 0.975551962852478),\n",
       " ('substituido', 0.9754981994628906)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vmodel_politica.wv.most_similar('corrupto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('injusto', 0.9937238693237305),\n",
       " ('permanecer', 0.9932953715324402),\n",
       " ('certamente', 0.9924558997154236),\n",
       " ('ir', 0.9908967018127441),\n",
       " ('nocao', 0.9898350834846497),\n",
       " ('venha', 0.9896763563156128),\n",
       " ('viver', 0.9896162152290344),\n",
       " ('aceitar', 0.9893770813941956),\n",
       " ('pensava', 0.9888630509376526),\n",
       " ('morrido', 0.9886140823364258)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vmodel_politica.wv.most_similar('inocente')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos corpus para o Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 1744\n"
     ]
    }
   ],
   "source": [
    "all_documents = []\n",
    "all_files = files_saude\n",
    "all_files.extend(files_politica)\n",
    "for file in all_files:\n",
    "    with open(file, 'r') as text_file:\n",
    "        document = ' '.join(text_file.readlines())\n",
    "        document = normalizer.lowercase(document)\n",
    "        document_tokens = normalizer.tokenize_words(document)\n",
    "        all_documents.append(document_tokens)\n",
    "print(\"Number of documents: {}\".format(len(all_documents)))\n",
    "tagged_documents = [TaggedDocument(words=d, tags=[str(i)]) for i, d in enumerate(all_documents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2vmodel = Doc2Vec(tagged_documents, vector_size=20, window=2, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 4: Uso do Doc2Vec\n",
    "\n",
    "#### Dados\tos\tdocumentos\t(textos) de\tcorporas\tdiferentes,\tutilize\tos\tvetores\tpara encontrar\tos\tdocumentos\tmais\tsimilares\n",
    "\n",
    "    - Exemplifique com três documentos e discuta os resultados. Ao ser ver, foram bons? Os documentos realmente são parecidos? O que poderia ser feito para melhorar os resultados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplos de documentos similiares aos exemplos\n",
      "Documentos similares ao documento: data/corpora/saude/drauziovarella_uol_com_br-cardiovascular-o-que-e-um-infarto-fulminante-.txt \n",
      "=========================================================\n",
      "\n",
      "data/corpora/saude/saude_abril_com_br-blog-alimente-se-com-ciencia-o-papel-dos-adocantes-na-dieta-e-sua-seguranca-de-consumo-.txt\n",
      "\n",
      "data/corpora/saude/saude_abril_com_br-blog-pet-saudavel-animais-exoticos-sao-seres-inteligentes-e-muito-especiais-.txt\n",
      "\n",
      "data/corpora/saude/drauziovarella_uol_com_br-entrevistas-2-nodulos-na-tireoide-entrevista-.txt\n",
      "\n",
      "data/corpora/saude/www1_folha_uol_com_br-equilibrioesaude-2017-03-1869080-dois-tercos-dos-casos-de-cancer-sao-por-falta-de-sorte_shtml.txt\n",
      "\n",
      "data/corpora/saude/drauziovarella_uol_com_br-entrevistas-2-cicatrizes-2-.txt\n",
      "=========================================================\n",
      "Exemplos de documentos similiares aos exemplos\n",
      "Documentos similares ao documento: data/corpora/saude/www1_folha_uol_com_br-equilibrioesaude-2017-11-1938873-metade-dos-jovens-brasileiros-entre-16-e-25-anos-tem-hpv-estima-pesquisa_shtml.txt \n",
      "=========================================================\n",
      "\n",
      "data/corpora/politica/www1_folha_uol_com_br-poder-2017-05-1887139-protesto-em-brasilia-termina-com-49-feridos-7-detidos-e-exercito-nas-ruas_shtml.txt\n",
      "\n",
      "data/corpora/politica/blogs_oglobo_globo_com-lauro-jardim-post-bolsonaro-americano-como-o-brasileiro-ve-trump-nas-redes-sociais_html.txt\n",
      "\n",
      "data/corpora/saude/noticias_uol_com_br-saude-ultimas-noticias-estado-2019-04-27-em-rato-exercicio-de-forca-controla-diabete_htm.txt\n",
      "\n",
      "data/corpora/politica/blogs_oglobo_globo_com-lauro-jardim-post-em-1992-bolsonaro-era-muito-mais-comportado_html#comments.txt\n",
      "\n",
      "data/corpora/saude/drauziovarella_uol_com_br-corpo-humano-tireoide-.txt\n",
      "=========================================================\n",
      "Exemplos de documentos similiares aos exemplos\n",
      "Documentos similares ao documento: data/corpora/saude/saude_abril_com_br-blog-cientistas-explicam-virus-da-gripe-por-que-todo-ano-temos-uma-luta-e-uma-vacina-diferente-.txt \n",
      "=========================================================\n",
      "\n",
      "data/corpora/saude/saude_abril_com_br-blog-cientistas-explicam-o-que-drogas-games-e-redes-sociais-tem-em-comum-.txt\n",
      "\n",
      "data/corpora/saude/saude_abril_com_br-blog-e-verdade-ou-fake-news-videos-mostram-como-salvar-vitimas-do-avc-com-uma-agulha-mas-sao-fake-.txt\n",
      "\n",
      "data/corpora/saude/saude_abril_com_br-blog-cientistas-explicam-a-semente-da-discordia-existe-mesmo-alimento-natural-.txt\n",
      "\n",
      "data/corpora/saude/saude_abril_com_br-blog-o-fim-das-dietas-o-melhor-pedaco-do-chocolate-e-o-ultimo-e-isso-afeta-o-emagrecimento-.txt\n",
      "\n",
      "data/corpora/saude/saude_abril_com_br-blog-cientistas-explicam-poliomielite-uma-gotinha-de-bom-senso-.txt\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "#numero de documentos similares que deseja procurar\n",
    "topn = 5\n",
    "\n",
    "#posicao do documento na lista all_documentos que deseja procurar documentos similares\n",
    "n_doc = 30\n",
    "n_doc1 = 125\n",
    "n_doc2 = 700\n",
    "\n",
    "print(\"Exemplos de documentos similiares aos exemplos\")\n",
    "print(\"Documentos similares ao documento: %s \" % all_files[n_doc])\n",
    "print(\"=========================================================\")\n",
    "similar_doc = d2vmodel.docvecs.most_similar(n_doc, topn=topn)\n",
    "for doc_num in similar_doc:\n",
    "    print(\"\")\n",
    "    print(all_files[int(doc_num[0])])\n",
    "print(\"=========================================================\")\n",
    "\n",
    "print(\"Exemplos de documentos similiares aos exemplos\")\n",
    "print(\"Documentos similares ao documento: %s \" % all_files[n_doc1])\n",
    "print(\"=========================================================\")\n",
    "similar_doc = d2vmodel.docvecs.most_similar(n_doc1, topn=topn)\n",
    "for doc_num in similar_doc:\n",
    "    print(\"\")\n",
    "    print(\"%dº Documento => %s\" % (int(doc_num, all_files[int(doc_num[0])])))\n",
    "print(\"=========================================================\")\n",
    "\n",
    "print(\"Exemplos de documentos similiares aos exemplos\")\n",
    "print(\"Documentos similares ao documento: %s \" % all_files[n_doc2])\n",
    "print(\"=========================================================\")\n",
    "similar_doc = d2vmodel.docvecs.most_similar(n_doc2, topn=topn)\n",
    "for doc_num in similar_doc:\n",
    "    print(\"\")\n",
    "    print(all_files[int(doc_num[0])])\n",
    "print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
