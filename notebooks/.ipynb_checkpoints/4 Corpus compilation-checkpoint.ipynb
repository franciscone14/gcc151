{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus compilation\n",
    "- text type and genres\n",
    "- characteristics according to task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requests in python\n",
    "import urllib3\n",
    "# Regular expression library\n",
    "import re\n",
    "# Transform html into a tree im memory\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "# Get just the text in a html document\n",
    "import justext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Disable https warning\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "# Pass as a browser \n",
    "user_agent = {'user-agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64)'}\n",
    "\n",
    "# Pool of boots to make requests\n",
    "http = urllib3.PoolManager(10, headers=user_agent)\n",
    "\n",
    "\n",
    "class Crawler:\n",
    "    \n",
    "    def __init__(self, corpus_path, max_files, seed_url, url_pattern):\n",
    "        self.corpus_path = corpus_path # corpus address\n",
    "        self.max_files = max_files # max amount of sizes\n",
    "        self.seed_url = seed_url # root url\n",
    "        self.url_pattern = url_pattern # Select links of interest\n",
    "        self.visited_links = [] # Hash to store viseted links\n",
    "        self.to_be_visited = [] # List of link\n",
    "        \n",
    "        # If path not exists create it\n",
    "        if not os.path.exists(self.corpus_path):\n",
    "            os.makedirs(self.corpus_path)\n",
    "        \n",
    "    def crawl(self):\n",
    "        first_urls = self.get_page(self.seed_url)\n",
    "        self.add_links(first_urls)\n",
    "        next_link = self.get_next_link()\n",
    "        \n",
    "        file_counter = 1\n",
    "        while next_link and file_counter < self.max_files:\n",
    "            links = self.get_page(next_link)\n",
    "            self.add_links(links)\n",
    "            next_link = self.get_next_link()\n",
    "            file_counter += 1\n",
    "        \n",
    "    \n",
    "    def get_page(self, url):\n",
    "        print(\"getting page {}\".format(url))\n",
    "        response = http.request('GET', url)\n",
    "\n",
    "        # store text content\n",
    "        paragraphs = justext.justext(response.data, justext.get_stoplist(\"Portuguese\"))\n",
    "        with open(\"{}/{}.txt\".format(self.corpus_path, url.replace(\".\", \"_\").replace(\"/\",\"-\")[8:]), \"w\") as output_file:\n",
    "            for paragraph in paragraphs:\n",
    "                # Boilerplate is everthing that is not the main text\n",
    "                if not paragraph.is_boilerplate:\n",
    "                    output_file.write(paragraph.text)\n",
    "        \n",
    "        # get links\n",
    "        soup = BeautifulSoup(response.data, 'html.parser')\n",
    "        \n",
    "        links = [link.get('href') for link in soup.findAll('a', attrs={'href': re.compile(self.url_pattern)})]\n",
    "        return links\n",
    "\n",
    "    def add_links(self, links):\n",
    "        links = list(set(links))\n",
    "        self.to_be_visited.extend([link for link in links if link not in self.visited_links])\n",
    "\n",
    "    def get_next_link(self):\n",
    "        next_link = self.to_be_visited.pop(0)\n",
    "        self.visited_links.append(next_link)\n",
    "        return next_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crawler_cultura = Crawler(\"data/corpora/cultura\", 500, \n",
    "                             \"https://www1.folha.uol.com.br/ilustrada/2019/04/morre-fotografo-alemao-conhecido-pelo-registro-de-megalopoles.shtml\", \n",
    "                            \"^https://www1.\\folha\\.uol\\.com\\.br/ilustrada/\")\n",
    "\n",
    "crawler_folha_politica = Crawler(\"data/corpora/politica\", 5000,\n",
    "                          \"https://www1.folha.uol.com.br/poder/2019/04/bolsonaro-minimiza-crise-com-mourao-e-diz-que-a-briga-e-por-quem-lava-a-louca.shtml\",\n",
    "                          \"^https://www1\\.folha\\.uol\\.com\\.br/poder/\\d+\")\n",
    "\n",
    "crawler_uol_politica = Crawler(\"data/corpora/politica\", 500, \"https://economia.uol.com.br/noticias/redacao/2019/04/25/reforma-da-previdencia-bpc-rural-abono.htm\",\n",
    "                              \"^https://economia\\.uol\\.com\\.br/noticias/\")\n",
    "\n",
    "crawler_g1_politica = Crawler(\"data/corpora/politica\", 500, \"https://g1.globo.com/politica/noticia/2019/04/25/mpf-divulga-estudo-que-revela-violacoes-de-direitos-de-indios-guarani-na-construcao-de-itaipu.ghtml\",\n",
    "                             \"https://g1\\.globo\\.com/politica/noticia/\\d+\")\n",
    "\n",
    "crawler_paragmatismo_politica = Crawler(\"data/corpora/politica\", 500, \"https://www.pragmatismopolitico.com.br/2019/04/ataques-carlos-bolsonaro-contra-mourao-twitter.html\",\n",
    "                                       \"^https://www\\.pragmatismopolitico\\.com\\.br/2019/\\d+\")\n",
    "\n",
    "crawler_oglobo_politica = Crawler(\"data/corpora/politica\", 500, \"https://blogs.oglobo.globo.com/lauro-jardim/post/bolsonaro-veta-campanha-do-banco-do-brasil-marcada-pela-diversidade-e-diretor-cai-veja-o-video-proibido.html\",\n",
    "                                 \"^https://blogs\\.oglobo\\.globo\\.com/\")\n",
    "\n",
    "crawler_carta_politica = Crawler(\"data/corpora/politica\", 500, \"https://www.cartacapital.com.br/politica/em-meio-a-ataques-de-carlos-bolsonaro-maia-nega-impeachment-de-mourao/\",\n",
    "                                \"^https://www\\.cartacapital\\.com\\.br/politica/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting page https://www1.folha.uol.com.br/ilustrada/2019/04/morre-fotografo-alemao-conhecido-pelo-registro-de-megalopoles.shtml\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "pop from empty list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0c6586d2fdc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcrawler_cultura\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrawl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# crawler_folha_politica.crawl()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# crawler_uol_politica.crawl()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# crawler_carta_politica.crawl()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# crawler_paragmatismo_politica.crawl()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-16e01e13e55a>\u001b[0m in \u001b[0;36mcrawl\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mfirst_urls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_links\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_urls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mnext_link\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_link\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mfile_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-16e01e13e55a>\u001b[0m in \u001b[0;36mget_next_link\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_link\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mnext_link\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_be_visited\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisited_links\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_link\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext_link\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from empty list"
     ]
    }
   ],
   "source": [
    "# crawler_cultura.crawl()\n",
    "crawler_folha_politica.crawl()\n",
    "# crawler_uol_politica.crawl()\n",
    "# crawler_carta_politica.crawl()\n",
    "# crawler_paragmatismo_politica.crawl()\n",
    "# crawler_oglobo_politica.crawl()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
